# ğŸµ VibeTune - AI-Powered Music Recommendation System

[![Next.js](https://img.shields.io/badge/Next.js-14-black?logo=next.js)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3.12.9-blue?logo=python)](https://www.python.org/)
[![Supabase](https://img.shields.io/badge/Supabase-Database-green?logo=supabase)](https://supabase.com/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue?logo=typescript)](https://www.typescriptlang.org/)

> VibeTune is an intelligent music recommendation platform that uses **multimodal emotion detection** (voice + facial expression) to suggest personalized music based on your current mood. It features multi-language support, interest-based filtering, and detailed mood analytics.

---

## ğŸŒŸ Key Features

- ğŸ­ **Multimodal Emotion Detection**: Combines voice (Wav2Vec2) and facial analysis (DeepFace) for accurate mood detection.
- ğŸµ **Smart Music Recommendations**: AI-powered song suggestions via Spotify API based on detected emotions.
- ğŸŒ **Multi-Language Support**: Prioritizes music in Bengali, Hindi, English, or your preferred languages.
- ğŸ¯ **Interest-Based Filtering**: Personalizes recommendations with genre preferences.
- ğŸ‘¤ **User Profiles & Playlists**: Save preferences, create playlists, and track listening history.
- ğŸ“Š **Mood Analytics**: Tracks your emotional patterns over time with visual insights.
- ğŸ”’ **Secure Authentication**: Powered by Supabase Auth with JWT tokens.
- ğŸ“± **Responsive Design**: Works seamlessly on desktop, tablet, and mobile devices.

---

## ğŸ—ï¸ System Architecture & Data Flow

This diagram shows the end-to-end flow, from user interaction on the frontend to data processing in the backend and communication with external services.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (Next.js - Port 3000)                                  â”‚
â”‚ components/mood/MoodDetectorPanelIntegrated.tsx                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ User clicks â”‚ â†’ â”‚ Record audio â”‚ â†’ â”‚ Capture image       â”‚    â”‚
â”‚ â”‚ "Detect"    â”‚   â”‚ (7s, 16kHz WAV)â”‚ â”‚ from <video> stream â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                 â†“               â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                   â”‚ lib/services/voiceEmotion.tsâ”‚
â”‚                                   â”‚ FormData with:          â”‚   â”‚
â”‚                                   â”‚ - audio_file (Blob)     â”‚   â”‚
â”‚                                   â”‚ - image_file (Blob)     â”‚   â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚ HTTP POST to http://localhost:8000/analyze-voice-and-face
                                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND (FastAPI - Port 8000)                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ server_api.py: @app.post("/analyze-voice-and-face")        â”‚  â”‚
â”‚ â”‚ 1. Middleware: middleware/supabase_auth.py (Verify JWT)    â”‚  â”‚
â”‚ â”‚ 2. Save temp files (audio.wav, image.jpg)                  â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â†“ (Parallel Execution)   â†“                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    â”‚ VOICE ANALYSIS   â”‚     â”‚ FACE ANALYSIS    â”‚                â”‚
â”‚    â”‚ voice_model/     â”‚     â”‚ video_model/     â”‚                â”‚
â”‚    â”‚ voice_api.py     â”‚     â”‚ face_expression.py                â”‚
â”‚    â”‚                  â”‚     â”‚                  â”‚                â”‚
â”‚    â”‚ 1. Load audio    â”‚     â”‚ 1. Load image    â”‚                â”‚
â”‚    â”‚ 2. Resample 16kHzâ”‚     â”‚ 2. Detect face   â”‚                â”‚
â”‚    â”‚ 3. Tokenize      â”‚     â”‚ 3. DeepFace      â”‚                â”‚
â”‚    â”‚ 4. Wav2Vec2      â”‚     â”‚ 4. Normalize     â”‚                â”‚
â”‚    â”‚ 5. Softmax       â”‚     â”‚                  â”‚                â”‚
â”‚    â”‚                  â”‚     â”‚                  â”‚                â”‚
â”‚    â”‚ Result: happy    â”‚     â”‚ Result: happy    â”‚                â”‚
â”‚    â”‚ (Confidence 0.87)â”‚     â”‚ (Confidence 0.78)â”‚                â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                          â†“                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚ EMOTION FUSION       â”‚                           â”‚
â”‚              â”‚ services/emotion_fusion.py                       â”‚
â”‚              â”‚                      â”‚                           â”‚
â”‚              â”‚ 1. Get agreement     â”‚ â†’ "Strong"                â”‚
â”‚              â”‚ 2. Calc weights      â”‚ â†’ (0.55, 0.45)            â”‚
â”‚              â”‚ 3. Choose emotion    â”‚ â†’ "happy"                 â”‚
â”‚              â”‚ 4. Combine scores    â”‚ â†’ Weighted Avg: 0.829     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                         â†“                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚ SPOTIFY SERVICE      â”‚                           â”‚
â”‚              â”‚ services/spotify_service.py                      â”‚
â”‚              â”‚                      â”‚                           â”‚
â”‚              â”‚ 1. Get lang priority â”‚ â†’ routes/user_preferences.py â”‚
â”‚              â”‚ 2. Map moodâ†’params   â”‚ â†’ valence, energy, etc.   â”‚
â”‚              â”‚ 3. API request       â”‚ â†’ RapidAPI (Spotify)      â”‚
â”‚              â”‚ 4. Parse tracks      â”‚ â†’ 20 tracks               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                         â†“                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚ BUILD & SEND RESPONSEâ”‚                           â”‚
â”‚              â”‚ {                    â”‚                           â”‚
â”‚              â”‚   "success": true,   â”‚                           â”‚
â”‚              â”‚   "combined_emotion": "happy", ...               â”‚
â”‚              â”‚ }                    â”‚                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP Response (JSON)
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (React/Next.js)                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Display Results in components/mood/MoodDetectorPanel...  â”‚    â”‚
â”‚ â”‚ - Emotion: HAPPY                                         â”‚    â”‚
â”‚ â”‚ - Confidence: 82.9%                                      â”‚    â”‚
â”‚ â”‚ - Agreement: Strong                                      â”‚    â”‚
â”‚ â”‚ - Music: Grid of 20 songs (components/music/SongCard.tsx)â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

Follow these steps to set up and run the project locally.

### Prerequisites

- **Node.js**: v18.0 or higher
- **Python**: v3.12.9 
- **Git**: For cloning the repository
- **Supabase Account**: For database and authentication (free tier is sufficient)
- **RapidAPI Account**: With a subscription to the Spotify API

### 1. Clone the Repository

```bash
git clone https://github.com/SubhobrataMaity/VibeTune.git
cd VibeTune
```

### 2. Backend Setup

```powershell
# Navigate to the Backend directory
cd Backend

#download the model from this link and paste this to Backend/voice_model/final_voice_model folder
-link - https://drive.google.com/drive/folders/1qDL5Arjf2JCxPJ6_73uU_5rOBU9QSzZP?usp=sharing

# Create enviroment in python
python -m venv venv

#activate a Python virtual environment
venv\Scripts\Activate.ps1

# Install the required dependencies
pip install -r requirements.txt

#for prisma generation
prisma generate

# Create the environment file from the example
paste the .env file to Backend/



# Edit the .env file with your credentials from Supabase and RapidAPI
# SUPABASE_URL=https://your-project-id.supabase.co
# SUPABASE_SERVICE_KEY=your-supabase-service-key
# SUPABASE_JWT_SECRET=your-supabase-jwt-secret
# RAPIDAPI_KEY=your-rapidapi-key
# RAPIDAPI_HOST=spotify81.p.rapidapi.com
# RAPIDAPI_URL=https://spotify81.p.rapidapi.com

# Start the backend server
python -m uvicorn server_api:app --reload --port 8000
```
The backend will be running at `http://localhost:8000`. You can access the API documentation at `http://localhost:8000/docs`.

### 3. Frontend Setup

```powershell
#open another powershell or terminal in vs code

# Navigate to the Frontend directory from the root
cd Frontend

# Install the required dependencies
npm install

#paste the .env.local file to the Frontend/
.env.local


# Edit the .env.local file with your Supabase credentials
# NEXT_PUBLIC_SUPABASE_URL=https://your-project-id.supabase.co
# NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key
# NEXT_PUBLIC_API_URL=http://localhost:8000

# Start the frontend development server
npm run dev
```
The frontend will be running at `http://localhost:3000`.

### 4. Database Setup

1.  **Create a Supabase Project**: Go to your [Supabase Dashboard](https://supabase.com/dashboard) and create a new project.
2.  **Get Credentials**: Find your Project URL, `anon` key, and `service_role` key in the "Project Settings" > "API" section.
3.  **Run SQL Schema**:
    *   Navigate to the "SQL Editor" in your Supabase project.
    *   Copy the entire content of `supabase_schema.sql` from the root of this repository.
    *   Paste it into the SQL Editor and click "Run".
    *   This will create all the necessary tables (`users`, `playlists`, `user_preferences`, etc.).

---

## ğŸ“ Project Structure

```
VibeTune/
â”œâ”€â”€ Backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ server_api.py                # Main application entry point & routes
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ .env.example                 # Environment variable template
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ supabase_auth.py         # JWT verification middleware
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                      # API route modules for DB operations
â”‚   â”‚   â”œâ”€â”€ playlists.py             # Playlist CRUD
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # Business logic
â”‚   â”‚   â”œâ”€â”€ emotion_fusion.py        # Emotion merging algorithm
â”‚   â”‚   â””â”€â”€ spotify_service.py       # Spotify API wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ video_model/                 # Facial emotion detection
â”‚   â”‚   â””â”€â”€ face_expression.py       # DeepFace integration
â”‚   â”‚
â”‚   â””â”€â”€ voice_model/                 # Voice emotion detection
â”‚       â”œâ”€â”€ voice_api.py             # Wav2Vec2 integration
â”‚       â””â”€â”€ final_voice_model/       # Pre-trained model files
â”‚
â”œâ”€â”€ Frontend/                         # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                     # Next.js 14 App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ (main)/              # Authenticated routes
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx         # Home page
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mood/page.tsx    # Mood detection page
â”‚   â”‚   â”‚   â”œâ”€â”€ login/page.tsx       # Login page
â”‚   â”‚   â”‚   â””â”€â”€ layout.tsx           # Root layout
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ mood/
â”‚   â”‚   â”‚   â”‚ â””â”€â”€ MoodDetectorPanelIntegrated.tsx # Main detector UI
â”‚   â”‚   â”‚   â”œâ”€â”€ music/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MusicRecommendations.tsx    # Displays song grid
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SongCard.tsx                # Individual song card
â”‚   â”‚   â”‚   â””â”€â”€ layout/
â”‚   â”‚   â”‚       â”œâ”€â”€ Navbar.tsx
â”‚   â”‚   â”‚       â””â”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â”œâ”€â”€ services/            # Frontend API service layer
â”‚   â”‚       â”‚   â”œâ”€â”€ auth.ts          # Supabase auth functions
â”‚   â”‚       â”‚   â”œâ”€â”€ spotify.ts       # Calls to backend for music
â”‚   â”‚       â”‚   â””â”€â”€ voiceEmotion.ts  # Calls to backend for mood analysis
â”‚   â”‚       â”œâ”€â”€ supabaseClient.ts    # Supabase client configuration
â”‚   â”‚       â””â”€â”€ utils.ts             # Utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json                 # Node dependencies
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ Docs/                             # Detailed documentation files
â”œâ”€â”€ README.md                         # This file
â””â”€â”€ supabase_schema.sql              # Database schema for Supabase
```

---

## ğŸ§ª Testing

A comprehensive testing guide with detailed scenarios for every feature can be found in `Docs/TestingGuide.md`. It covers:
-   Home Page and Mood Detection tests.
-   Search and Cross-Page Persistence tests.
-   API, Performance, and Mobile Responsiveness tests.
-   Error recovery and edge case scenarios.

---

